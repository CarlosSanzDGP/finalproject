{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las funciones anteriores. Poner a parte e importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(imagen,size,output=False):\n",
    "    im = Image.open(imagen)\n",
    "    rgb_image = RGBA_a_RGB(im)\n",
    "    im_rgb = rgb_image.resize(size)\n",
    "    \n",
    "    if not output:\n",
    "        return im_rgb \n",
    "    onlyfiles = [f for f in listdir(output) if isfile(join(output, f))]\n",
    "    if image not in onlyfiles:\n",
    "        im.save(output)\n",
    "        return im_rgb\n",
    "    else:\n",
    "        print(\"file already exists, continuing to next one\") \n",
    "        return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGBA_a_RGB(image1):\n",
    "    if image1.mode == \"RGBA\":\n",
    "        background = Image.new(\"RGB\", image1.size, (255, 255, 255))\n",
    "        background.paste(image1, mask = image1.split()[3])\n",
    "        background.save(f\"{image1}\", \"JPEG\", quality=100)\n",
    "        rgb_image = Image.open(f\"{image1}\")\n",
    "        return rgb_image\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(image):\n",
    "    im_np= np.asarray(image)\n",
    "    one_line=im_np.ravel()\n",
    "    return one_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths={\"black\":\"INPUT/black/\",\n",
    "      \"white\":\"INPUT/white/\",\n",
    "      \"green\":\"INPUT/green/\",\n",
    "      \"red\":\"INPUT/red/\"}\n",
    "images={}\n",
    "for color,path in paths.items():\n",
    "    images[color]=[]\n",
    "    for im in listdir(path):\n",
    "        if im.endswith(\"jpg\"):\n",
    "            #size=(64,64)\n",
    "            a=resize_image(path+im,(64,64))\n",
    "            images[color].append(np.asarray(a))\n",
    "    images[color]=np.array(images[color])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(image):\n",
    "    im_np= np.asarray(image)\n",
    "    one_line=im_np.ravel()\n",
    "    return one_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.concatenate(list(images.values()),axis=0)\n",
    "y = np.concatenate([[k]* v.shape[0] for k,v in images.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui empieza realmente. Division entre la x y la y para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (8388, 64, 64, 3)\n",
      "8388 train samples\n",
      "2097 test samples\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 64, 64\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "# Prepare data to feed the NN\n",
    "num_classes = 4\n",
    "\n",
    "# Ask keras which format to use depending on used backend and arrange data as expected\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = x_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = x_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Incoming data is in uint8. Cast the input data images to be floats in range [0.0-1.0]  \n",
    "X_train = tf.keras.utils.normalize(X_train,axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test,axis=1)\n",
    "#X_train = X_train.astype('float32') / 255\n",
    "#X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 64, 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies funciona pero lo vamos a cambiar asi que lo #comento y queda fuera\n",
    "y_train=pd.get_dummies(pd.Series(y_train)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.get_dummies(pd.Series(y_test)).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiar el getdummies por el onehotencoder de felipe. then fit_transform\n",
    " from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ESPERA ESPERA ESPERA \n",
    "# HACER onehotencoder DESPUES de hacer getdummies? tiene sentido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['black'],\n",
       "       ['black'],\n",
       "       ['black'],\n",
       "       ...,\n",
       "       ['red'],\n",
       "       ['red'],\n",
       "       ['red']], dtype='<U5')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= y.reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(y).toarray()\n",
    "# OJO AQUI AQUIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "#sto se lo voy a hacer a ytrain ytest para poder pasarselo al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_black', 'x0_green', 'x0_red', 'x0_white'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['green']], dtype='<U5')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[0,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['black', 'black', 'white', ..., 'white', 'red', 'black'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que utilizar el label encoder para que reconozca los 4 valores\n",
    "#hay que dropear la primera columna para que no la haga? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       black\n",
       "1       black\n",
       "2       white\n",
       "3       black\n",
       "4       white\n",
       "        ...  \n",
       "8383    black\n",
       "8384    black\n",
       "8385    white\n",
       "8386      red\n",
       "8387    black\n",
       "Length: 8388, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo intentamos con el label encoder\n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, ..., 3, 2, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_le=le.fit_transform(pd.Series(y_train)) \n",
    "y_train_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el array ahora tiene cada valor por un numero. Y no podia haber nombrado a cada key del diccionario asi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-3f2facdaad8b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-3f2facdaad8b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    np.array(y_train_le), dtype = np.str)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para correr el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "84/84 [==============================] - 12s 142ms/step - loss: 0.0298 - accuracy: 0.9812 - val_loss: 0.0261 - val_accuracy: 0.9800\n",
      "Epoch 2/20\n",
      "84/84 [==============================] - 13s 151ms/step - loss: 0.0274 - accuracy: 0.9835 - val_loss: 0.0717 - val_accuracy: 0.9471\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 14s 161ms/step - loss: 0.0242 - accuracy: 0.9844 - val_loss: 0.0272 - val_accuracy: 0.9800\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0261 - accuracy: 0.9846 - val_loss: 0.0326 - val_accuracy: 0.9809\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 14s 166ms/step - loss: 0.0226 - accuracy: 0.9855 - val_loss: 0.0308 - val_accuracy: 0.9800\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 14s 166ms/step - loss: 0.0208 - accuracy: 0.9884 - val_loss: 0.0274 - val_accuracy: 0.9824\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0222 - accuracy: 0.9865 - val_loss: 0.0256 - val_accuracy: 0.9852\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 14s 166ms/step - loss: 0.0195 - accuracy: 0.9886 - val_loss: 0.0299 - val_accuracy: 0.9843\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0174 - accuracy: 0.9897 - val_loss: 0.0284 - val_accuracy: 0.9819\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0167 - accuracy: 0.9899 - val_loss: 0.0299 - val_accuracy: 0.9833\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0158 - accuracy: 0.9903 - val_loss: 0.0253 - val_accuracy: 0.9857\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0143 - accuracy: 0.9909 - val_loss: 0.0627 - val_accuracy: 0.9642\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0161 - accuracy: 0.9911 - val_loss: 0.0269 - val_accuracy: 0.9838\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0132 - accuracy: 0.9928 - val_loss: 0.0714 - val_accuracy: 0.9461\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0145 - accuracy: 0.9912 - val_loss: 0.0250 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0125 - accuracy: 0.9926 - val_loss: 0.0479 - val_accuracy: 0.9833\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.0136 - accuracy: 0.9912 - val_loss: 0.0372 - val_accuracy: 0.9838\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 14s 166ms/step - loss: 0.0120 - accuracy: 0.9925 - val_loss: 0.0322 - val_accuracy: 0.9847\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0123 - accuracy: 0.9927 - val_loss: 0.0277 - val_accuracy: 0.9852\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0106 - accuracy: 0.9945 - val_loss: 0.0317 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f59286dc780>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3426697e-19, 7.3386260e-17, 1.3422586e-22, 1.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[56].shape\n",
    "model.predict(np.array([X_test[403]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
