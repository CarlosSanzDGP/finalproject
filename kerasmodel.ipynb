{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "#from __future__ import print_function\n",
    "\n",
    "from SRC.transform import *\n",
    "#estas son mis funciones traidas del jupyter contiguo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths={\"black\":\"INPUT/black/\",\n",
    "      \"white\":\"INPUT/white/\",\n",
    "      \"green\":\"INPUT/green/\",\n",
    "      \"red\":\"INPUT/red/\"}\n",
    "images={}\n",
    "for color,path in paths.items():\n",
    "    images[color]=[]\n",
    "    for im in listdir(path):\n",
    "        if im.endswith(\"jpg\"):\n",
    "            #size=(64,64)\n",
    "            a=resize_image(path+im,(64,64))\n",
    "            images[color].append(np.asarray(a))\n",
    "    images[color]=np.array(images[color])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.concatenate(list(images.values()),axis=0)\n",
    "y = np.concatenate([[k]* v.shape[0] for k,v in images.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division entre la x y la y para test\n",
    "### Ojo, normalmente convertiriamos el onehotencoder antes de esta division para ahorrarnos un paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (8388, 64, 64, 3)\n",
      "8388 train samples\n",
      "2097 test samples\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 64, 64\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "# Prepare data to feed the NN\n",
    "num_classes = 4\n",
    "\n",
    "# Ask keras which format to use depending on used backend and arrange data as expected\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = x_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = x_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Incoming data is in uint8. Cast the input data images to be floats in range [0.0-1.0]  \n",
    "X_train = tf.keras.utils.normalize(X_train,axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test,axis=1)\n",
    "#X_train = X_train.astype('float32') / 255\n",
    "#X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#red neuronal propiamente dicha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 64, 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de cambio de las y para poder utilizarlas en el modelo. \n",
    "### Las necesitamos en el formato de array sin strings y getdummies no nos sirvio ya que \n",
    "### no podiamos obtener el color con posterioridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo aqui para que quede reflejado el modulo que utilizamos\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['black', 'white', 'black', ..., 'white', 'white', 'black'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['black'],\n",
       "       ['white'],\n",
       "       ['black'],\n",
       "       ...,\n",
       "       ['white'],\n",
       "       ['white'],\n",
       "       ['black']], dtype='<U5')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos el reshape, luego onehot encoder, luego fit y por ultimo toarray\n",
    "y_test= y_test.reshape(-1, 1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##3\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = enc.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#por fin y_test esta en la forma que queremos\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora hago lo mismo con y Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['black', 'green', 'white', ..., 'white', 'red', 'white'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = enc.transform(y_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ha funcionado. Tenemos y_test e y_train en el formato que necesitabamos\n",
    "# podiamos haberlo hecho antes de dividir el split del train pero he decidido hacerlo dos veces para practicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_black', 'x0_green', 'x0_red', 'x0_white'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['green']], dtype='<U5')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[0,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo para para correr el modelo de red neuronal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 0.3419 - accuracy: 0.7114 - val_loss: 0.1902 - val_accuracy: 0.8522\n",
      "Epoch 2/20\n",
      "84/84 [==============================] - 13s 151ms/step - loss: 0.2038 - accuracy: 0.8501 - val_loss: 0.1488 - val_accuracy: 0.8784\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 14s 164ms/step - loss: 0.1700 - accuracy: 0.8763 - val_loss: 0.1196 - val_accuracy: 0.9075\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.1399 - accuracy: 0.9019 - val_loss: 0.0934 - val_accuracy: 0.9299\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 15s 173ms/step - loss: 0.1081 - accuracy: 0.9231 - val_loss: 0.0708 - val_accuracy: 0.9537\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 14s 171ms/step - loss: 0.0880 - accuracy: 0.9437 - val_loss: 0.0615 - val_accuracy: 0.9599\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0709 - accuracy: 0.9529 - val_loss: 0.0503 - val_accuracy: 0.9695\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.0638 - accuracy: 0.9613 - val_loss: 0.0513 - val_accuracy: 0.9680\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.0583 - accuracy: 0.9652 - val_loss: 0.0417 - val_accuracy: 0.9766\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0512 - accuracy: 0.9703 - val_loss: 0.0469 - val_accuracy: 0.9719\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 14s 170ms/step - loss: 0.0474 - accuracy: 0.9723 - val_loss: 0.0336 - val_accuracy: 0.9771\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0416 - accuracy: 0.9752 - val_loss: 0.0312 - val_accuracy: 0.9809\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0402 - accuracy: 0.9768 - val_loss: 0.0442 - val_accuracy: 0.9738\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0422 - accuracy: 0.9760 - val_loss: 0.0312 - val_accuracy: 0.9766\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.0335 - accuracy: 0.9794 - val_loss: 0.0305 - val_accuracy: 0.9804\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.0305 - accuracy: 0.9826 - val_loss: 0.0375 - val_accuracy: 0.9757\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 14s 167ms/step - loss: 0.0285 - accuracy: 0.9825 - val_loss: 0.0302 - val_accuracy: 0.9809\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.0285 - accuracy: 0.9834 - val_loss: 0.0280 - val_accuracy: 0.9843\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 14s 169ms/step - loss: 0.0291 - accuracy: 0.9824 - val_loss: 0.0330 - val_accuracy: 0.9795\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 14s 168ms/step - loss: 0.0230 - accuracy: 0.9864 - val_loss: 0.0292 - val_accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7dd221a9b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3661310e-14, 1.0887863e-12, 1.0000000e+00, 3.4082523e-16]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[45].shape\n",
    "model.predict(np.array([X_test[2000]]))\n",
    "#nos dice cual es la prediccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_black', 'x0_green', 'x0_red', 'x0_white'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names()\n",
    "# y hay que recordar que los colores marcados son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['black']], dtype='<U5')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[9.9999976e-01, 6.4836332e-09, 1.1157968e-09, 1.2618054e-12]])\n",
    "#nos da el resultado mas probable en una tuple. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3661310e-14, 1.0887863e-12, 1.0000000e+00, 3.4082523e-16]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([X_test[2000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[9.9999976e-01, 6.4836332e-09, 1.1157968e-09, 1.2618054e-12]])[0][0]\n",
    "# le digo que me muestre solo el primer elemento, que es el color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2000].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.16860769, 0.17039556, 0.16977151],\n",
       "        [0.16208582, 0.16408352, 0.16413284],\n",
       "        [0.18283584, 0.19340441, 0.19027679],\n",
       "        ...,\n",
       "        [0.10889563, 0.12785336, 0.12889548],\n",
       "        [0.14306867, 0.1496268 , 0.15035371],\n",
       "        [0.12678506, 0.13105385, 0.13056816]],\n",
       "\n",
       "       [[0.16271232, 0.16809292, 0.16639857],\n",
       "        [0.16091973, 0.16636246, 0.16524939],\n",
       "        [0.18955774, 0.1947112 , 0.19413375],\n",
       "        ...,\n",
       "        [0.11635423, 0.13637692, 0.13754619],\n",
       "        [0.13325824, 0.13959595, 0.14021751],\n",
       "        [0.13838631, 0.14274018, 0.14228582]],\n",
       "\n",
       "       [[0.16978677, 0.17039556, 0.16977151],\n",
       "        [0.16675016, 0.16750193, 0.16748249],\n",
       "        [0.19493527, 0.1947112 , 0.19541941],\n",
       "        ...,\n",
       "        [0.11486251, 0.13467221, 0.13581605],\n",
       "        [0.1299881 , 0.13625234, 0.13683877],\n",
       "        [0.13755765, 0.14190545, 0.14144885]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.05777466, 0.06102003, 0.06296162],\n",
       "        [0.05597208, 0.05925238, 0.06141025],\n",
       "        [0.06318591, 0.06664611, 0.06942532],\n",
       "        ...,\n",
       "        [0.08801153, 0.1039874 , 0.10467351],\n",
       "        [0.10627958, 0.11201112, 0.11234294],\n",
       "        [0.10606855, 0.11018541, 0.10964378]],\n",
       "\n",
       "       [[0.05895374, 0.06217135, 0.06408594],\n",
       "        [0.05947034, 0.06267079, 0.0647599 ],\n",
       "        [0.06587468, 0.06925969, 0.07199662],\n",
       "        ...,\n",
       "        [0.09024911, 0.10654447, 0.10726872],\n",
       "        [0.09646916, 0.10198028, 0.10220674],\n",
       "        [0.10441123, 0.10851593, 0.10796983]],\n",
       "\n",
       "       [[0.06013281, 0.06332268, 0.06521025],\n",
       "        [0.05947034, 0.06267079, 0.0647599 ],\n",
       "        [0.06587468, 0.06925969, 0.07199662],\n",
       "        ...,\n",
       "        [0.08651981, 0.10228269, 0.10294337],\n",
       "        [0.10382698, 0.10950341, 0.10980889],\n",
       "        [0.10938319, 0.11352436, 0.11299168]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_colour (im):\n",
    "    x = model.predict(np.array([im]))\n",
    "    \n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (car_colour (X[600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-3e238f67da9e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-3e238f67da9e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    enc.inverse_transform([[1. 0. 0. 0.]])[0][0]\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "enc.inverse_transform([[1. 0. 0. 0.]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las imagenes deben ser metidas como el array de arriba, de X[2000]\n",
    "def car_colour (im):\n",
    "    x = model.predict(np.array([im]))\n",
    "    y = enc.inverse_transform([x[0]])[0][0]\n",
    "    if y=='black':\n",
    "        frase\n",
    "        return f'The color of the car of the picture is {y}, like my soul'\n",
    "    elif y== \"red\":\n",
    "        return f'The color of the car of the picture is {y}, like the communist you are'\n",
    "    elif y== \"yellow\":\n",
    "        return f'The color of the car of the picture is {y}, like \"hielo\" in english'\n",
    "    elif y==\"white\":\n",
    "        return f\"The color of the car of the picture is {y}, like the white russian I'll have this evening\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the car of the picture is white, like the white russian I'll have this evening\n"
     ]
    }
   ],
   "source": [
    "print (car_colour (X[7002]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10485, 64, 64, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que alguien me explique porque funciona cuando lo hago todo del tiron en la misma funcion \n",
    "# pero no cuando lo hago por partes.\n",
    "\n",
    "#le puedo poner un random choice para que diga distintas estupideces al azar segun el color\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
